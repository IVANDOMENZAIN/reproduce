---
title: "Supplementary Material"
author: "Benjamin J. Sanchez, Petri-Jaan Lahtvee, Kate Campbell, Sergo Kasvandik, Rosemary Yu, Ivan Domenzain, Aleksej Zelezniak and Jens Nielsen"
header-includes:
- \usepackage{float}
- \renewcommand{\thefigure}{S\arabic{figure}}
- \renewcommand{\thetable}{S\arabic{table}}
- \floatplacement{figure}{H}
- \floatplacement{table}{H}
bibliography: ../doc/paper/bibliography.bib
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = "png", dpi = 600)
```

# Summary

Here we will go through the typical way of deducing protein abundances [fmol/sample] from SILAC/iBAQ data, and compare it to rescaling values to a fix total protein abundance based on MS intensities, to assess the usefulness of the external standard curve and iBAQ data. The main observation that comes from this is that as MS measurements are so variable, it's impossible to find a unique ES curve, hence normalizing to a fixed total protein abundance is as good as using the "optimal" fit from the ES curve. We can then use the MS intensity directly and bypass both the ES curve and the iBAQ values.
<br>

# Loading and pre-processing data

## Loading packages

```{r warning = FALSE, message = FALSE, results = FALSE}
library(plyr)
library(knitr)
library(biomaRt)
library(vioplot)
library(kableExtra)
```

```{r echo=FALSE}
read_chunk('loadData.R')
read_chunk('processData.R')
read_chunk('plotData.R')
read_chunk('mainFigures.R')
```

## Loading UPS2

The commercial kit brings 10.6 ug of protein, however only 1.1 ug is injected in the MS:

```{r loadUPS2}
```

## Loading iBAQ data

In the iBAQ data (IS+ES) there are 6 samples: 3 technical replicates (`batch1`, `batch2` & `batch3`) and each of them is processed with 2 different MS methods `top5` & `top10`. We will have then 6 different ES curves:

* top5_batch1
* top5_batch2
* top5_batch3
* top10_batch1
* top10_batch2
* top10_batch3

```{r loadIBAQdata}
```

## Getting the ES data

In each sample of the iBAQ data there are:

* 6 ug of IS: yeast samples, all marked; i.e. will appear in the heavy fraction (H)
* 1.1 ug of ES: universal protein standard (UPS2) unmarked; i.e. will appear in the light fraction (L)

```{r splitIBAQdata}
```

## Loading SILAC data

There are 18 different samples:

* 3 biological replicates (`R1`, `R2` & `R3`)
* each with 3 technical replicates (`batch1`, `batch2` & `batch3`)
* each estimated with a different MS method (`top5` & `top10`)

Each injected sample consisted of:

* 6 ug of IS (detected in the H fraction)
* 6 ug of actual sample (detected in the L fraction)

```{r loadSILACdata}
```

## Getting number of theoretical peptides

We can obtain the number of theoretical peptides for each of the proteins if we remove the UPS2 sequences and label from the MaxQuant search, which leads the software to report only the iBAQ intensities of the proteins. We then divide the raw intensity with the iBAQ intensity to get the desired number:

```{r loadNtheoPeptides}
```

We then merge this information with the IS data:

```{r}
ISdata <- merge(NTP, ISdata, by = 'Protein.IDs', all.x = FALSE, all.y = TRUE)
```

## Loading ribosomal proteins

We use a list of ribosomal genes based on previous work [@Jenner2012]:

```{r loadRibProteins}
```

# Methods evaluated

## Method 1: iBAQ

Let's start by using the computed iBAQ abundances available in the MaxQuant [@Cox2008] output file, which are inferred using an ES curve of the UPS2 proteins (in the L fraction) [@Schwanhausser2011]. As the data already comes in fmol/sample, the only thing missing is to use the values from the IS (H fraction) together with the normalized L/H ratios in the SILAC data for getting absolute abundances in each sample of the SILAC data (fmol/sample), by doing:

`abundance(sample) = (L/H)ratio * abundance(IS)`

```{r getSampleAbundance}
```

```{r}
SILACdata <- getSampleAbundance(SILACdata,ISdata,'iBAQ')
```

## Method 2: Rescaling iBAQ values

As iBAQ values don't add up always to the same totals (Figure \ref{fig:tot-IS}), we should asses the benefits of rescaling all of these values to add up to the injected amounts:

`abundance = (iBAQ abundance)*(injected amount)/(sum of all iBAQ abundances*MW values)`

```{r rescaleData}
```

```{r}
ESdata    <- rescaleData(ESdata,'Abundance.iBAQ.ES.','iBAQrescaled.ES.',1.1e6) #1.1 ug
ISdata    <- rescaleData(ISdata,'Abundance.iBAQ.IS.','iBAQrescaled.IS.',6e6)   #6 ug
```

We now use the absolute abundances from the IS (fmol/sample) to infer absolute abundances in each sample of the SILAC data (fmol/sample):

```{r}
SILACdata <- getSampleAbundance(SILACdata,ISdata,'iBAQrescaled')
```

## Method 3: TPA

The alternative: To skip iBAQ values and ES curves entirely, and to assume all MS intensities summed up together (mass-wise) is proportional to the injected amount in ug. This is known as the total protein approach (TPA) [@Wisniewski2014a]:

`abundance = (MS intensity)*(injected amount)/(sum of all MS intensities*MW values)`

```{r}
ESdata    <- rescaleData(ESdata,'Intensity.L.T4h_','TPA.ES.',1.1e6) #1.1 ug
ISdata    <- rescaleData(ISdata,'Intensity.H.T4h_','TPA.IS.',6e6)   #6 ug
SILACdata <- getSampleAbundance(SILACdata,ISdata,'TPA')
```

## Method 4: Normalized TPA

We will also try out to first normalize all MS intensitiy values by the sequence length, as proxy for number of theoretical peptides:

```{r normalizeIntensities}
```

```{r}
ESdata <- normalizeIntensities(ESdata,'Sequence.length')
ISdata <- normalizeIntensities(ISdata,'Sequence.length')
```

Now we rescale the data as before:

```{r}
ESdata    <- rescaleData(ESdata,'normInt.length.L.T4h_','TPAnorm.ES.',1.1e6) #1.1 ug
ISdata    <- rescaleData(ISdata,'normInt.length.H.T4h_','TPAnorm.IS.',6e6)   #6 ug
SILACdata <- getSampleAbundance(SILACdata,ISdata,'TPAnorm')
```

Note that for methods 3 and 4 we have essentially created a linear model:

`abundance = m*MSintensity`, where `m = (6 ug)/(sum of all MSintensities*MWs)`

`log(abundance) = log(MSintensity) + log(m)` -> linear model with a = 1 and b = log(m) in the log space.

## Additional methods

As we do not have the normalized intensities for the MaxQuant calculations of iBAQ abundances, we will use an additional method only for comparing the ES curves quality. Abundance of the IS here is computed by building a log-log standard curve for the ES and applying it to the normalized MS intensities from the IS (H fraction). Note that said ES curve MUST have slope = 1, as the underlying assumption is that MS intensities are linearly proportional to the mass of the corresponding proteins, therefore:

`moles = m*MSint`

`log10(moles) = log10(m*MSint)`

`log10(moles) = log10(MSint) + log10(m)`

So if the fit is done in the log space, we fix the ES curve to always have slope = 1, and find the corresponding fit for the intercept:

```{r interpolateAbundance}
```

```{r}
ISdata    <- interpolateAbundance(ISdata,'normInt.length.H.T4h_','Interp.IS.')
ESdata    <- interpolateAbundance(ESdata,'normInt.length.L.T4h_','Interp.ES.')
SILACdata <- getSampleAbundance(SILACdata,ISdata,'Interp')
```

Finally, in the case of the IS data, we can also get the intensity values normalized by the number of theoretical peptides (which we will use later for validating our assumption of sequence length as proxy for number of theoretical peptides):

```{r}
ISdata    <- normalizeIntensities(ISdata,'theo.peptides')
ISdata    <- rescaleData(ISdata,'normInt.Ntheo.H.T4h_','TPANtheo.IS.',6e6)   #6 ug
SILACdata <- getSampleAbundance(SILACdata,ISdata,'TPANtheo')
```


# Method comparison

## Preliminary comparison

Let's plot the data between methods: For that we define a function that gives all possible combinations between replicates. For instance, for biological replicates, the text in the variable's label regarding biological replicate (`.R1.1`, `.R2.1` and `.R3.1`) will be first removed, and then 2 columns will be paired up if the rest of the name matches (meaning it's the same technical replicate/MS method but 2 different biological replicates). We can also use it to compare between methods by removing the method's name:

```{r getReplicateData}
```

We also need a couple of plotting functions:

```{r getColors}
```

```{r plotScatter}
```

```{r plotVariability}
```

```{r general-comp, fig.height = 6, fig.width = 10, fig.align = "center", fig.cap = "\\label{fig:general-comp}Comparison of predictions [fmol/sample] between all methods (on log10 scale). Blue is a FC lower than 2, yellow between 2 and 10, and gray over 10."}
abundanceIBAQ <- SILACdata[,c(1,grep('Abundance.iBAQ.R',names(SILACdata)))]
abundanceIR   <- SILACdata[,c(1,grep('Abundance.iBAQrescaled.R',names(SILACdata)))]
abundanceTPA  <- SILACdata[,c(1,grep('Abundance.TPA.R',names(SILACdata)))]
abundanceTPAN <- SILACdata[,c(1,grep('Abundance.TPAnorm.R',names(SILACdata)))]
IRvsIBAQ   <- cbind(abundanceIBAQ[,-1],abundanceIR[,-1])
TPAvsIBAQ  <- cbind(abundanceIBAQ[,-1],abundanceTPA[,-1])
TPANvsIBAQ <- cbind(abundanceIBAQ[,-1],abundanceTPAN[,-1])
TPAvsIR    <- cbind(abundanceIR[,-1],abundanceTPA[,-1])
TPANvsIR   <- cbind(abundanceIR[,-1],abundanceTPAN[,-1])
TPANvsTPA  <- cbind(abundanceTPA[,-1],abundanceTPAN[,-1])
IBAQname   <- 'Method 1: iBAQ'
IRname     <- 'Method 2: iBAQ rescaled'
TPAname    <- 'Method 3: TPA'
TPANname   <- 'Method 4: TPA normalized'
par(mfrow = c(2,3), mar = c(4,4,2,1), cex = 1)
plotVariability(IRvsIBAQ, c('iBAQ.R','iBAQrescaled.R'), '', IBAQname, IRname, FALSE)
plotVariability(TPAvsIBAQ, c('iBAQ.R','TPA.R'), '', IBAQname, TPAname, FALSE)
plotVariability(TPANvsIBAQ, c('iBAQ.R','TPAnorm.R'), '', IBAQname, TPANname, FALSE)
plotVariability(TPAvsIR, c('iBAQrescaled.R','TPA.R'), '', IRname, TPAname, FALSE)
plotVariability(TPANvsIR, c('iBAQrescaled.R','TPAnorm.R'), '', IRname, TPANname, FALSE)
plotVariability(TPANvsTPA, c('TPA.R','TPAnorm.R'), '', TPAname, TPANname, FALSE)
```

Comparing sequence length Vs the number of theoretical peptides:

```{r plotVsLength}
```

```{r general-Ntheo, fig.height = 4, fig.width = 4, fig.align = "center", fig.cap = "\\label{fig:general-Ntheo}Number of theoretical peptides Vs sequence length for all proteins."}
par(mfrow = c(1,1), mar = c(4,4,2,1), cex = 1)
plotVsLength(ISdata,'theo.peptides','Number of theoretical peptides')
```

We see that in fact sequence length works as a good proxy for the number of theoretical peptides. We can further see this comparing predictions between both normalization methods:

```{r general-goodProxy, fig.height = 4, fig.width = 4, fig.align = "center", fig.cap = "\\label{fig:general-goodProxy}Comparison of predictions [fmol/sample] (on log10 scale) between normalizing methods (sequence length Vs number of theoretical peptides). Blue is a FC lower than 2, yellow between 2 and 10, and gray over 10."}
abundanceNtheo <- SILACdata[,c(1,grep('Abundance.TPANtheo.R',names(SILACdata)))]
normComb       <- cbind(abundanceNtheo[,-1],abundanceTPAN[,-1])
nameNtheo      <- 'Normalizing by num theo peptides'
nameLength     <- 'Normalizing by sequence length'
par(mfrow = c(1,1), mar = c(4,4,2,1), cex = 1)
plotVariability(normComb, c('TPANtheo.R','TPAnorm.R'), '', nameNtheo, nameLength, FALSE)
```

Let's now see the predicted abundances of all samples compared to the sequence length:

```{r general-length, fig.height = 7, fig.width = 7, fig.align="center", fig.cap = "\\label{fig:general-length}Predicted abundances [fmol/sample] (in the log10 space) Vs sequence length for all proteins and all methods."}
par(mfrow = c(2,2), mar = c(3,3,2,1), cex = 1)
sampleNames <- c('Abundance.iBAQ.R','Abundance.iBAQrescaled.R',
                 'Abundance.TPA.R','Abundance.TPAnorm.R')
titleNames <- c(IBAQname,IRname,TPAname,TPANname)
plotVsLength(SILACdata,sampleNames,titleNames)
```

We can see that methods 1,2 and 4 all have similar correlation values, while method 3 correlates less than the other 3 methods to protein length.
<br>

## Accuracy evaluation

Let's now compare accuracy. First, we compare the ES values predicted by each method to the actual UPS2 values:

```{r plotESdata}
```

```{r accuracy-ups2, fig.height = 7, fig.width = 7, fig.align="center", fig.cap = "\\label{fig:accuracy-ups2}Comparison of predicted Vs real abundance values [fmol/sample] from UPS2, according to all methods. Blue is a FC lower than 2, yellow between 2 and 10, and gray over 10."}
par(mfrow = c(2,2), mar = c(4,4,2,1), cex = 1)
FCups2IBAQ <- plotESdata(ESdata,'iBAQ',IBAQname)
FCups2IR   <- plotESdata(ESdata,'iBAQrescaled',IRname)
FCups2TPA  <- plotESdata(ESdata,'TPA',TPAname)
FCups2TPAN <- plotESdata(ESdata,'TPAnorm',TPANname)
```

We see that all predictions from methods 1, 2 and 4 are very similar; by using ES curves (methods 1-2) we don't gain much prediction power than if we just rescale the data (method 4). However, method 3 performs significantly worse.

Now, let's see how are the predictions of ribosomal subunits stoichiometry. For that first we create dataframes with only ribosomal proteins:

```{r getRPdata}
```

```{r}
rpIBAQ  <- getRPdata(abundanceIBAQ,RP)
rpIR    <- getRPdata(abundanceIR,RP)
rpTPA   <- getRPdata(abundanceTPA,RP)
rpTPAN  <- getRPdata(abundanceTPAN,RP)
rpNtheo <- getRPdata(abundanceNtheo,RP)
```

Now we can plot for each method the corresponding data:

```{r plotRPdata}
```

```{r accuracy-ribosome, fig.height = 10, fig.width = 8, fig.align="center", fig.cap = "\\label{fig:accuracy-ribosome}Comparison of predicted ribosomal subunit abundances [fmol/sample], according to all methods. Colors correspond to different technical replicates. The median value is displayed with a segmented line, and the median fold change to that line for all data is displayed."}
par(mfrow = c(5,1), mar = c(4,4,2,1), cex = 1)
FCrpIBAQ  <- plotRPdata(rpIBAQ,IBAQname)
FCrpIR    <- plotRPdata(rpIR,IRname)
FCrpTPA   <- plotRPdata(rpTPA,TPAname)
FCrpTPAN  <- plotRPdata(rpTPAN,TPANname)
FCrpNtheo <- plotRPdata(rpNtheo,nameNtheo)
```

These distributions are not very different between them (with exception of method 3), as we can see in the cumulative distributions:

```{r plotCumulativeDistrib}
```

```{r accuracy-cdf, warning = FALSE, fig.height = 5, fig.width = 8, fig.align = "center", fig.cap = "\\label{fig:accuracy-cdf}Cumulative distributions of absolute fold changes for both accuracy evaluation metrics: differences of predicted Vs experimental values of UPS2 (left) and differences to median value in ribosomal measurements (right). A fold change of 2 is indicated with a vertical segmented line. Colors represent the methods: 1) iBAQ (blue), 2) iBAQ rescaled (gray), 3) TPA (brown) and 4) TPA normalized (yellow)."}
ups2FC <- data.frame(FCups2IBAQ,FCups2IR,FCups2TPA,FCups2TPAN)
rpFC   <- data.frame(FCrpIBAQ,FCrpIR,FCrpTPA,FCrpTPAN)
par(mfrow = c(1,2), mar = c(4,4,2,1), cex = 1)
plotCumulativeDistrib(ups2FC,'UPS2 abundance error')
plotCumulativeDistrib(rpFC,'Ribosomal stoichiometry variability')
```

## Protein totals

Let's now take a look at the total detected protein amount in each of the 6 samples of IS, for all methods:

```{r plotTotalProt}
```

```{r tot-IS, fig.height = 3, fig.width = 10, fig.align = "center", fig.cap = "\\label{fig:tot-IS}Total detected protein amounts in all 6 IS, according to all methods."}
par(mfcol = c(1,4), mar = c(1,2.5,2,1), cex = 1)
ISnames <- c('Abundance.iBAQ.IS','Abundance.iBAQrescaled.IS',
             'Abundance.TPA.IS','Abundance.TPAnorm.IS')
for(i in 1:length(ISnames)) {
  plotTotalProt(ISdata,ISnames[i],titleNames[i])
}
```

Let's also take a look at the total detected protein amount of each of the 18 samples, colored by the original ES curve used for the calibration (Figure \ref{fig:tot-IS}):

```{r tot-samples, fig.height = 3, fig.width = 10, fig.align = "center", fig.cap = "\\label{fig:tot-samples}Total detected protein amounts in all 18 samples, according to all methods."}
par(mfcol = c(1,4), mar = c(1,2.5,2,1), cex = 1)
sampleNames <- c('Abundance.iBAQ.R..1_','Abundance.iBAQrescaled.R..1_',
                 'Abundance.TPA.R..1_','Abundance.TPAnorm.R..1_')
for(i in 1:length(sampleNames)) {
  plotTotalProt(SILACdata,sampleNames[i],titleNames[i])
}
```

In both figures \ref{fig:tot-IS} and \ref{fig:tot-samples}, the total detected protein seems to vary quite a bit among samples calculated with iBAQ, and as expected this reduces if we rescale (methods 2, 3 and 4). Note that for all cases the total amount of protein detected in the samples is lower than the amount detected in the internal standard, due to more proteins detected in the internal standard (as the latter is a mix of different conditions and not just one sample).

## ES curves

Let's now take a look at the ES data + standard curves from method 4, compared to the alternative method (using an ES curve on the normalized MS intensities). For that we need:

* A function for plotting a linear fit (with a slope = 1):

```{r plotLM}
```

* A function for plotting the external standard:

```{r plotES}
```

* A function for plotting all 6 external standards (together or separate):

```{r plotAllES}
```

Note that we cannot look at the ES curves of methods 1 and 2 as we do not have the values for the normalized MS intensities by MaxQuant (the software does not provide them).

```{r es-separate, fig.align = "center", fig.cap = "\\label{fig:es-separate}ES curves (log10(abundance [fmol/sample]) in y-axis Vs log10(normalized MS intensity) in x-axis) based on the 31/ 48 UPS2 proteins that were detected and measured by the MS, with (gray) and without (blue) rescaling. Within each of the 4 orders of magnitude, each symbol corresponds to a different protein."}
#All 6 MS intensity values from the IS (H fraction):
ISpos <- grep('normInt.length.H.T4h',names(ISdata))
Hdata   <- ISdata[,ISpos]*ISdata$Mol..weight..kDa.
scaling <- 6e6/colSums(Hdata, na.rm = TRUE)
plotAllES(ESdata,'normInt.length.L.T4h_',scaling,FALSE)
```

The blue fits give us the transformation from light (L) MS intensity of the UPS2 proteins to abundance (fmol/sample) with the traditional approach. But they don't look the best (considering they are in log10 space), many other curves (as the gray fits) can almost equally well fit that data. Let's see everything in the same plot:

```{r es-together, fig.align = "center", fig.cap = "\\label{fig:es-together}ES curves (log10(abundance [fmol/sample]) in y-axis Vs log10(MS intensity) in x-axis), with (gray) and without (blue) rescaling. Average coefficient of variation (CVm) within each protein is shown in the upper left corner."}
plotAllES(ESdata,'normInt.length.L.T4h_',scaling,TRUE)
```

Note that the MS precision is quite poor: the same protein detection can vary almost a full order of magnitude in some cases. This supports the idea that an alternative linear fit can replace the original ES curve, as both are an approximation anyway.

## Evaluating precision

We now display the variability of the final abundance data between biological and technical replicates, for all methods, using variability plots and a PCA:

```{r plotPCA}
```

```{r plotAllVariability}
```

```{r precision-all, fig.height = 12, fig.width = 10, fig.align = "center", fig.cap = "\\label{fig:precision-all}Comparison of data variability from 1) iBAQ (1st row), 2) rescaling iBAQ (2nd row), 3) TPA (3rd row) and 4) normalized TPA (4th row). In the variability plots (left and middle columns, log10(abundance [fmol/sample]) both in the x-axis and y-axis), 2 abundance values for a given protein are plotted if they belong to the same replicate (biological or technical, respectively). Blue is a FC lower than 2, yellow between 2 and 10, and gray over 10. In the PCA plots (right column), colors refer to technical replicates and shapes to biological replicates."}
par(mfrow = c(5,3), mar = c(0, 1, 1.5, 0), cex = 1)
plotAllVariability(abundanceIBAQ,TRUE)
plotAllVariability(abundanceIR,FALSE)
plotAllVariability(abundanceTPA,FALSE)
plotAllVariability(abundanceTPAN,FALSE)
plotAllVariability(abundanceNtheo,FALSE)
```

We see a lower median fold change in the technical replicates + a better separation of the "technical clusters" in the PCA when we use method 3 or 4 (PC1 represents less variability). This means that by using rescaled MS data (methods 3 or 4) we achieve lower variability between technical replicates than with methods 1 and 2. This is confirmed by looking at the breakdown of proteins by method:

```{r FCbreakdownRep}
```

```{r FCbreakdown}
```

```{r breakdown, warning = FALSE}
col1 <- FCbreakdown(abundanceIBAQ)
col2 <- FCbreakdown(abundanceIR)
col3 <- FCbreakdown(abundanceTPA)
col4 <- FCbreakdown(abundanceTPAN)
breakdown <- cbind(col1,col2,col3,col4)
colnames(breakdown)  <- c("Method 1","Method 2","Method 3","Method 4")
row.names(breakdown) <- c("FC < 2","2 < FC < 10","10 < FC",
                          "FC < 2","2 < FC < 10","10 < FC",
                          "FC < 2","2 < FC < 10","10 < FC")
tablecap <- paste("Protein breakdown by method and type of replicate.",
                  "For each protein, the maximum fold change is considered.")
kable(breakdown, "latex", caption = tablecap, booktabs = T) %>%
  kable_styling(latex_options = "hold_position") %>%
  group_rows("Biological Replicates", 1, 3) %>%
  group_rows("Technical Replicates", 4, 6) %>%
  group_rows("All Replicates", 7, 9)

```

## Evaluating technical precision

Let's look further into the reduction of technical variability, by looking at violin plots for the coefficients of variation:

```{r getCVs}
```

```{r precision-violin, fig.width = 8, fig.align = "center", fig.cap = "\\label{fig:precision-violin}Violin plots of CVs between batches. Colors represent the methods: 1) iBAQ (blue), 2) iBAQ rescaled (gray), 3) TPA (brown) and 4) TPA normalized (yellow)."}
par(mfrow = c(1,1), mar = c(4,4,1.5,0.5))
names      <- c('_batch1','_batch2','_batch3')
CVbatchIBAQ <- getCVs(abundanceIBAQ[,-1],names)
CVbatchIR   <- getCVs(abundanceIR[,-1],names)
CVbatchTPA  <- getCVs(abundanceTPA[,-1],names)
CVbatchTPAN <- getCVs(abundanceTPAN[,-1],names)
plot(1, 1, xlim = c(0,4.5), ylim = c(-1,2.2), type = 'n',
     xaxs = 'i', xaxt = 'n', xlab = '', ylab = 'log10(CV)')
axis(side = 1, at = 1:4, labels = gsub('Method ','',titleNames))
cols <- getColors(4)
vioplot(CVbatchIBAQ, at = 1, col = cols[1], add = TRUE)
vioplot(CVbatchIR,   at = 2, col = cols[2], add = TRUE)
vioplot(CVbatchTPA,  at = 3, col = cols[3], add = TRUE)
vioplot(CVbatchTPAN, at = 4, col = cols[4], add = TRUE)
```

We can see all of the above in a summarized plot with cumulative distributions:

```{r precision-tech, fig.width = 4, fig.align = "center", fig.cap = "\\label{fig:precision-tech}Fold change cumulative distributions for all methods. A fold change of 2 is indicated with a vertical segmented line. Colors represent the methods: 1) iBAQ (blue), 2) iBAQ rescaled (gray), 3) TPA (brown) and 4) TPA normalized (yellow)."}
par(mfrow = c(1,1), mar = c(4,4,1.5,0.5))
FCtechIBAQ <- getReplicateData(abundanceIBAQ[,-1],names,2,FALSE)
FCtechIR   <- getReplicateData(abundanceIR[,-1],names,2,FALSE)
FCtechTPA  <- getReplicateData(abundanceTPA[,-1],names,2,FALSE)
FCtechTPAN <- getReplicateData(abundanceTPAN[,-1],names,2,FALSE)
techFC     <- data.frame(FCtechIBAQ[,2],FCtechIR[,2],FCtechTPA[,2],FCtechTPAN[,2])
plotCumulativeDistrib(techFC,'Technical variability')
```

We can also look at technical variability by plotting each FC to the basal abundance, together with a "UPS2 window" that shows the abundance levels that are detected by the UPS2:

```{r plotFCvsAbundance}
```

We can now compare again the methods:

```{r precision-abundance, fig.height = 3, fig.width = 10, fig.align = "center", fig.cap = "\\label{fig:precision-abundance}Fold change Vs abundances for all methods. The detection window of UPS2 and the UPS2 datapoints are highlighted in black."}
par(mfrow = c(1,4), mar = c(4,4,1.5,0.5))
for(i in 1:length(sampleNames)) {
  tmp <- plotFCvsAbundance(SILACdata,ESdata,sampleNames[i],titleNames[i],FALSE)
}
```

We see that in all cases more than 80% of the data falls within the detection range of UPS2, which is good. However, all datasets look similar in shape, so instead let's look at the trend of the data with the help of smooth splines:

```{r plotSplines}
```

Plotting now all data together with the smoothing splines for each method:

```{r precision-splines, fig.width = 4, fig.align = "center", fig.cap = "\\label{fig:precision-splines}Fold change Vs abundances for all methods + smoothing splines. Colors represent the methods: 1) iBAQ (blue), 2) iBAQ rescaled (gray), 3) TPA (brown) and 4) TPA normalized (yellow). The detection window of UPS2 is highlighted in yellow."}
par(mfrow = c(1,1), mar = c(4,4,1.5,0.5))
plotSplines(SILACdata,ESdata)
```

We see that method 3 (normalized TPA) has less overall variability than the both iBAQ and rescaled iBAQ, both for lowly and highly abundant proteins.

In conclusion, we can skip entirely the UPS2 data and just assume that the normalized MS intensities should always adds up to a given protein amount. With this, we can reproduce very closely the ES curves, and achieve more consistent results across samples. In this approach, the iBAQ run is only used to do the rescaling, but this could be equally performed with any SILAC run.

# Main figures of manuscript

Figure 1:

```{r figure1, results="hide", warning = FALSE}
```

Figure 2:

```{r figure2, results="hide", warning = FALSE}
```

# References
